
# ğŸ“š Native Language QA â€” RAG++ with Multi-turn Conversation

A **Retrieval-Augmented Generation (RAG)** chatbot that:
- Indexes **native language documents** (PDF, DOCX, TXT)
- Uses **OCR** for scanned pages
- Extracts **summaries** and **entities**
- Answers questions by **retrieving fresh context** from *all* indexed docs every time
- Supports **multi-turn conversation** with follow-up Q&A

---

## ğŸš€ How it works

âœ… **Architecture**  
- **Vector Store:** Documents are split & embedded using **Cohere embeddings** (`llama-index-embeddings-cohere`).
- **Storage:** The vector index is saved locally for fast retrieval.
- **Retriever:** On each user query, the retriever searches **all indexed chunks**.
- **LLM:** A **Cohere LLM** generates the final answer using both the userâ€™s question and retrieved context.
- **Chat Memory:** Uses a simple conversation history to handle follow-up questions.

âœ… **Tools Used**
- [Cohere](https://cohere.com) â€” for embeddings & LLM completions.
- [LlamaIndex](https://www.llamaindex.ai/) â€” for vector store, retriever, and orchestration.
- [FAISS](https://github.com/facebookresearch/faiss) â€” optional for local vector storage backend.
- **OCR:** `pytesseract` + `pdf2image` + `PyMuPDF` for page text extraction.
- [Streamlit](https://streamlit.io) â€” for the local web UI.

---

## ğŸŒ Native Language Support

- Any language your documents are written in will be embedded as raw text.
- OCR processes **scanned pages**, converting non-searchable PDFs to plain text.
- As long as Cohereâ€™s embedding & generation models understand the language, your QA works.
- This makes the pipeline flexible for **Arabic, French, English**, etc.

---

## âš™ï¸ Key Features

- ğŸ” **Cross-document:** Every query re-searches **all** indexed pages â€” no stale cache.
- ğŸ§© **Hybrid chunks:** Uses page-level + chunk-level text + OCR to get the best signal.
- ğŸ—£ï¸ **Multi-turn chat:** Tracks chat history so follow-ups stay in context â€” but **always** retrieves fresh docs.
- ğŸ“‘ **Rich metadata:** Shows file name, folder, page number, summary & entities for transparency.

---

## ğŸ·ï¸ Limitations & Improvements

- **Trial API Limits:** The free Cohere API has low rate & quota limits â†’ production needs a paid plan.
- **Chain-of-thought:** Cross-passage reasoning can be improved with advanced prompt chaining.
- **Chunking:** For huge docs, more granular chunking & smart overlap could boost accuracy.
- **Better memory:** Right now the chat memory is simple â†’ can be expanded with full conversation trees.
- **Deployment:** Runs locally on Streamlit â€” production should use a secure backend.

---

## ğŸ–¥ï¸ How to Run

1ï¸âƒ£ **Install dependencies**
```bash
pip install -r requirements.txt
```

2ï¸âƒ£ **Set your API key**  

Get your Cohere API key and **add it to your environment**:

```bash
Replace your key in config.py

Here: COHERE_API_KEY = os.getenv("COHERE_API_KEY", "your_cohere_api_key")
```

3ï¸âƒ£ **Run the app**
```bash
streamlit run main.py
```

4ï¸âƒ£ **Open in your browser:**  
[http://localhost:8501](http://localhost:8501)

---

## ğŸ“‚ Project Structure

.
â”œâ”€â”€ cohere_client.py   # Wraps Cohere API: embed, summarize, extract entities, chat
â”œâ”€â”€ ingestion.py       # Loads docs, runs OCR, builds vector index
â”œâ”€â”€ query_engine.py    # Retrieves relevant chunks, calls Cohere LLM with context
â”œâ”€â”€ main.py            # Streamlit UI with multi-turn conversation
â”œâ”€â”€ test_script.py     # Local test script for single-turn & follow-ups
â”œâ”€â”€ config.py          # Reads Cohere API key
â”œâ”€â”€ requirements.txt   # All Python dependencies
â””â”€â”€ .gitignore         # Ignores venv, cache, API secrets
â””â”€â”€ storage/           # Saved vector index

---

## âœ… Example

- **Q:** Who is Charbel?  
- **A:** [Full bio from CV]

- **Q:** What is The Phoenix Alliance?  
- **A:** [Details from the Phoenix doc â€” cross-doc tested!]

- **Q:** Whatâ€™s his phone number? *(Follow-up)*  
- **A:** [Pulls from same CV â€” chat memory + fresh search]

---

## ğŸ§© Tests

Run the included test script to verify:

```bash
python test_script.py
```

---

## ğŸ—‚ï¸ Tech Stack

- **Python** â€” main glue
- **Streamlit** â€” web UI
- **LlamaIndex** â€” vector store & retrieval
- **Cohere** â€” embeddings, summarization, entity extraction, final LLM answers
- **PyMuPDF + pytesseract** â€” robust PDF text extraction with OCR fallback

---

## ğŸ¤ Contributing

Feel free to fork, tweak chunking, switch to OpenAI, or wrap as an API.
PRs are welcome!

---

## ğŸ“„ License

This project is provided as a technical demo â€” adjust and adapt for your needs!

---

## ğŸ“¬ Questions?

Message Charbel LEBBOUS | charbellebbousf@gmail.com | [\[YOUR GITHUB HANDLE\]](https://github.com/CharbelLebbous)

Happy building! ğŸš€

---

**Made with â¤ï¸ and Cohere**